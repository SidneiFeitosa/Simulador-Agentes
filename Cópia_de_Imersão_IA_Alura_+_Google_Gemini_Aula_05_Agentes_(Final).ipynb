{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SidneiFeitosa/Simulador-Agentes/blob/main/C%C3%B3pia_de_Imers%C3%A3o_IA_Alura_%2B_Google_Gemini_Aula_05_Agentes_(Final).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip -q install google-genai"
      ],
      "metadata": {
        "id": "UCCbECexLk_h"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura a API Key do Google Gemini\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "NfCqHo1tLk8P"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura o cliente da SDK do Gemini\n",
        "\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "MODEL_ID = \"gemini-2.0-flash\""
      ],
      "metadata": {
        "id": "bV4w0H5TLk5g"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pergunta ao Gemini uma informa√ß√£o mais recente que seu conhecimento\n",
        "\n",
        "from IPython.display import HTML, Markdown\n",
        "\n",
        "# Perguntar pro modelo quando √© a pr√≥xima imers√£o de IA ###############################################\n",
        "resposta = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents='Quando √© a pr√≥xima Imers√£o IA com Google Gemini da Alura?',\n",
        ")\n",
        "\n",
        "# Exibe a resposta na tela\n",
        "display(Markdown(f\"Resposta:\\n {response.text}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "Y9cBAz02xZt9",
        "outputId": "1e72c319-fa3a-422f-e668-4515a906801d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Resposta:\n A pr√≥xima Imers√£o IA com Google Gemini da Alura acontecer√° entre os dias **12 e 16 de maio de 2025**. As inscri√ß√µes est√£o abertas at√© o dia 11 de maio.\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pergunta ao Gemini uma informa√ß√£o utilizando a busca do Google como contexto\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents='Quando √© a pr√≥xima Imers√£o IA com Google Gemini da Alura?',\n",
        "    config={\"tools\": [{\"google_search\": {}}]}\n",
        ")\n",
        "\n",
        "# Exibe a resposta na tela\n",
        "display(Markdown(f\"Resposta:\\n {response.text}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "lc2JPA92xbnp",
        "outputId": "b6dea89e-bf3a-4c21-f626-d8eefe82dfd5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Resposta:\n A pr√≥xima Imers√£o IA com Google Gemini da Alura aconteceu de 12 a 16 de maio de 2025. As inscri√ß√µes estavam abertas at√© o dia 11 de maio de 2025.\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibe a busca\n",
        "print(f\"Busca realizada: {response.candidates[0].grounding_metadata.web_search_queries}\")\n",
        "# Exibe as URLs nas quais ele se baseou\n",
        "print(f\"P√°ginas utilizadas na resposta: {', '.join([site.web.title for site in response.candidates[0].grounding_metadata.grounding_chunks])}\")\n",
        "print()\n",
        "display(HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "6Cg0KNJGMgC5",
        "outputId": "b49cbd71-f0ed-4cff-b7c2-e300f24ab7c0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Busca realizada: ['Pr√≥xima imers√£o IA Alura Google Gemini', 'Alura imers√£o IA Google Gemini datas']\n",
            "P√°ginas utilizadas na resposta: thallesbenicio.com.br, eucapacito.com.br, convergenciadigital.com.br, tecmundo.com.br, youtube.com, alura.com.br\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              ".container {\n",
              "  align-items: center;\n",
              "  border-radius: 8px;\n",
              "  display: flex;\n",
              "  font-family: Google Sans, Roboto, sans-serif;\n",
              "  font-size: 14px;\n",
              "  line-height: 20px;\n",
              "  padding: 8px 12px;\n",
              "}\n",
              ".chip {\n",
              "  display: inline-block;\n",
              "  border: solid 1px;\n",
              "  border-radius: 16px;\n",
              "  min-width: 14px;\n",
              "  padding: 5px 16px;\n",
              "  text-align: center;\n",
              "  user-select: none;\n",
              "  margin: 0 8px;\n",
              "  -webkit-tap-highlight-color: transparent;\n",
              "}\n",
              ".carousel {\n",
              "  overflow: auto;\n",
              "  scrollbar-width: none;\n",
              "  white-space: nowrap;\n",
              "  margin-right: -12px;\n",
              "}\n",
              ".headline {\n",
              "  display: flex;\n",
              "  margin-right: 4px;\n",
              "}\n",
              ".gradient-container {\n",
              "  position: relative;\n",
              "}\n",
              ".gradient {\n",
              "  position: absolute;\n",
              "  transform: translate(3px, -9px);\n",
              "  height: 36px;\n",
              "  width: 9px;\n",
              "}\n",
              "@media (prefers-color-scheme: light) {\n",
              "  .container {\n",
              "    background-color: #fafafa;\n",
              "    box-shadow: 0 0 0 1px #0000000f;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #1f1f1f;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #ffffff;\n",
              "    border-color: #d2d2d2;\n",
              "    color: #5e5e5e;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #d8d8d8;\n",
              "    border-color: #b6b6b6;\n",
              "  }\n",
              "  .logo-dark {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
              "  }\n",
              "}\n",
              "@media (prefers-color-scheme: dark) {\n",
              "  .container {\n",
              "    background-color: #1f1f1f;\n",
              "    box-shadow: 0 0 0 1px #ffffff26;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #fff;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #2c2c2c;\n",
              "    border-color: #3c4043;\n",
              "    color: #fff;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #464849;\n",
              "    border-color: #53575b;\n",
              "  }\n",
              "  .logo-light {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
              "  }\n",
              "}\n",
              "</style>\n",
              "<div class=\"container\">\n",
              "  <div class=\"headline\">\n",
              "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
              "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
              "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
              "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
              "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
              "  </div>\n",
              "  <div class=\"carousel\">\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXG8IG1cQO-8j-EKzJGHCMAFjP3bnMQTkIdyqy4GT4LH2jcgTkT5J2Oul0YVnI3guxFsNZPi0yX_GqqSZlzWHW7NXhJPaO6l-K09UNH9yOw0H-KOatI-0B2TgLfRH7BmhepzpiGx8SZgpW24go4AO6oXaBk0nnNO7aJhYmbC20N955ibLpY9BWwyFgijOjXULvcUY0n0o11qH77pks1blyQJGTe7J9QlL14G9ks=\">Alura imers√£o IA Google Gemini datas</a>\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFSelHJY8c9ZQAnc4FitKPFlPv1A4tlJJCuYVoOUz6uY3X1ekJ6QjorY6yiZdFnUb-fvYP64Ypu10CEBaiVNJLcrP08xuSkPuToQ_dkd40RyFHY-3zNt2pMQEvHYH-tHl1TarDpLlyZcz3h8qMARY5xf9E2yIbVbBY5tNJSKzDzcRXlfKczrdz-qkZU5bfaNuBNKAl28IcXMairasD9WhNGWNIu1k8xRq4LcXOeSO7o4ODo\">Pr√≥xima imers√£o IA Alura Google Gemini</a>\n",
              "  </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar Framework de agentes do Google ################################################\n",
        "!pip install -q google-adk"
      ],
      "metadata": {
        "id": "a1eRPalxEnj7"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "aePV2bdfDeoW"
      },
      "outputs": [],
      "source": [
        "from google.adk.agents import Agent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.tools import google_search\n",
        "from google.genai import types  # Para criar conte√∫dos (Content e Part)\n",
        "from datetime import date\n",
        "import textwrap # Para formatar melhor a sa√≠da de texto\n",
        "from IPython.display import display, Markdown # Para exibir texto formatado no Colab\n",
        "import requests # Para fazer requisi√ß√µes HTTP\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o auxiliar que envia uma mensagem para um agente via Runner e retorna a resposta final\n",
        "def call_agent(agent: Agent, message_text: str) -> str:\n",
        "    # Cria um servi√ßo de sess√£o em mem√≥ria\n",
        "    session_service = InMemorySessionService()\n",
        "    # Cria uma nova sess√£o (voc√™ pode personalizar os IDs conforme necess√°rio)\n",
        "    session = session_service.create_session(app_name=agent.name, user_id=\"user1\", session_id=\"session1\")\n",
        "    # Cria um Runner para o agente\n",
        "    runner = Runner(agent=agent, app_name=agent.name, session_service=session_service)\n",
        "    # Cria o conte√∫do da mensagem de entrada\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=message_text)])\n",
        "\n",
        "    final_response = \"\"\n",
        "    # Itera assincronamente pelos eventos retornados durante a execu√ß√£o do agente\n",
        "    for event in runner.run(user_id=\"user1\", session_id=\"session1\", new_message=content):\n",
        "        if event.is_final_response():\n",
        "          for part in event.content.parts:\n",
        "            if part.text is not None:\n",
        "              final_response += part.text\n",
        "              final_response += \"\\n\"\n",
        "    return final_response"
      ],
      "metadata": {
        "id": "_xP4lWhsS5ko"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o auxiliar para exibir texto formatado em Markdown no Colab\n",
        "def to_markdown(text):\n",
        "  text = text.replace('‚Ä¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "8dosiodaxfFR"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################\n",
        "# --- Agente 1: Buscador de Not√≠cias --- #\n",
        "##########################################\n",
        "def agente_buscador(topico, data_de_hoje):\n",
        "\n",
        "    buscador = Agent(\n",
        "        name=\"agente_buscador\",\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        instruction=\"\"\"\n",
        "        Voc√™ √© um assistente de pesquisa. A sua tarefa √© usar a ferramenta de busca do google (google_search)\n",
        "        para recuperar as √∫ltimas not√≠cias de lan√ßamentos muito relevantes sobre o t√≥pico abaixo.\n",
        "        Foque em no m√°ximo 5 lan√ßamentos relevantes, com base na quantidade e entusiasmo das not√≠cias sobre ele.\n",
        "        Se um tema tiver poucas not√≠cias ou rea√ß√µes entusiasmadas, √© poss√≠vel que ele n√£o seja t√£o relevante assim\n",
        "        e pode ser substitu√≠do por outro que tenha mais.\n",
        "        Esses lan√ßamentos relevantes devem ser atuais, de no m√°ximo um m√™s antes da data de hoje.\n",
        "        \"\"\",\n",
        "        description=\"Agente que busca informa√ß√µes no Google\",\n",
        "        tools=[google_search]\n",
        "    )\n",
        "\n",
        "    entrada_do_agente_buscador = f\"T√≥pico: {topico}\\nData de hoje: {data_de_hoje}\"\n",
        "\n",
        "    lancamentos = call_agent(buscador, entrada_do_agente_buscador)\n",
        "    return lancamentos"
      ],
      "metadata": {
        "id": "o8bqIfi_DyH8"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################\n",
        "# --- Agente 2: Planejador de posts --- #\n",
        "################################################\n",
        "def agente_planejador(topico, lancamentos_buscados):\n",
        "    planejador = Agent(\n",
        "        name=\"agente_planejador\",\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        # Inserir as instru√ß√µes do Agente Planejador #################################################\n",
        "        instruction=\"\"\"\n",
        "        Voc√™ √© um planejador de conte√∫do, especialista em redes sociais. Com base na lista de\n",
        "        lan√ßamentos mais recentes e relevantes buscador, voc√™ deve:\n",
        "        usar a ferramenta de busca do Google (google_search) para criar um plano sobre\n",
        "        quais s√£o os pontos mais relevantes que poder√≠amos abordar em um post sobre\n",
        "        cada um deles. Voc√™ tamb√©m pode usar o (google_search) para encontrar mais\n",
        "        informa√ß√µes sobre os temas e aprofundar.\n",
        "        Ao final, voc√™ ir√° escolher o tema mais relevante entre eles com base nas suas pesquisas\n",
        "        e retornar esse tema, seus pontos mais relevantes, e um plano com os assuntos\n",
        "        a serem abordados no post que ser√° escrito posteriormente.\n",
        "        \"\"\",\n",
        "        description=\"Agente que planeja posts\",\n",
        "        tools=[google_search]\n",
        "    )\n",
        "\n",
        "    entrada_do_agente_planejador = f\"T√≥pico:{topico}\\nLan√ßamentos buscados: {lancamentos_buscados}\"\n",
        "    # Executa o agente\n",
        "    plano_do_post = call_agent(planejador, entrada_do_agente_planejador)\n",
        "    return plano_do_post"
      ],
      "metadata": {
        "id": "y3VO1uo5_ghO"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################\n",
        "# --- Agente 3: Redator do Post --- #\n",
        "######################################\n",
        "def agente_redator(topico, plano_de_post):\n",
        "    redator = Agent(\n",
        "        name=\"agente_redator\",\n",
        "        model=\"gemini-2.5-pro-preview-03-25\",\n",
        "        instruction=\"\"\"\n",
        "            Voc√™ √© um Redator Criativo especializado em criar posts virais para redes sociais.\n",
        "            Voc√™ escreve posts para a empresa Alura, a maior escola online de tecnologia do Brasil.\n",
        "            Utilize o tema fornecido no plano de post e os pontos mais relevantes fornecidos e, com base nisso,\n",
        "            escreva um rascunho de post para Instagram sobre o tema indicado.\n",
        "            O post deve ser engajador, informativo, com linguagem simples e incluir 2 a 4 hashtags no final.\n",
        "            \"\"\",\n",
        "        description=\"Agente redator de posts engajadores para Instagram\"\n",
        "    )\n",
        "    entrada_do_agente_redator = f\"T√≥pico: {topico}\\nPlano de post: {plano_de_post}\"\n",
        "    # Executa o agente\n",
        "    rascunho = call_agent(redator, entrada_do_agente_redator)\n",
        "    return rascunho"
      ],
      "metadata": {
        "id": "uOqlg2TRLVh1"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################\n",
        "# --- Agente 4: Revisor de Qualidade --- #\n",
        "##########################################\n",
        "def agente_revisor(topico, rascunho_gerado):\n",
        "    revisor = Agent(\n",
        "        name=\"agente_revisor\",\n",
        "        model=\"gemini-2.5-pro-preview-03-25\",\n",
        "        instruction=\"\"\"\n",
        "            Voc√™ √© um Editor e Revisor de Conte√∫do meticuloso, especializado em posts para redes sociais, com foco no Instagram.\n",
        "            Por ter um p√∫blico jovem, entre 18 e 30 anos, use um tom de escrita adequado.\n",
        "            Revise o rascunho de post de Instagram abaixo sobre o t√≥pico indicado, verificando clareza, concis√£o, corre√ß√£o e tom.\n",
        "            Se o rascunho estiver bom, responda apenas 'O rascunho est√° √≥timo e pronto para publicar!'.\n",
        "            Caso haja problemas, aponte-os e sugira melhorias.\n",
        "            \"\"\",\n",
        "        description=\"Agente revisor de post para redes sociais.\"\n",
        "    )\n",
        "    entrada_do_agente_revisor = f\"T√≥pico: {topico}\\nRascunho: {rascunho_gerado}\"\n",
        "    # Executa o agente\n",
        "    texto_revisado = call_agent(revisor, entrada_do_agente_revisor)\n",
        "    return texto_revisado"
      ],
      "metadata": {
        "id": "_aTb1SdkLeT6"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_de_hoje = date.today().strftime(\"%d/%m/%Y\")\n",
        "\n",
        "print(\"üöÄ Iniciando o Sistema de Cria√ß√£o de Posts para Instagram com 4 Agentes üöÄ\")\n",
        "\n",
        "# --- Obter o T√≥pico do Usu√°rio ---\n",
        "topico = input(\"‚ùì Por favor, digite o T√ìPICO sobre o qual voc√™ quer criar o post de tend√™ncias: \")\n",
        "\n",
        "# Inserir l√≥gica do sistema de agentes ################################################\n",
        "if not topico:\n",
        "    print(\"Voc√™ esqueceu de digitar o t√≥pico!\")\n",
        "else:\n",
        "    print(f\"Maravilha! Vamos ent√£o criar o post sobre novidades em {topico}\")\n",
        "\n",
        "    lancamentos_buscados = agente_buscador(topico, data_de_hoje)\n",
        "    print(\"\\n--- üìù Resultado do Agente 1 (Buscador) ---\\n\")\n",
        "    display(to_markdown(lancamentos_buscados))\n",
        "    print(\"--------------------------------------------------------------\")\n",
        "\n",
        "    plano_de_post = agente_planejador(topico, lancamentos_buscados)\n",
        "    print(\"\\n--- üìù Resultado do Agente 2 (Planejador) ---\\n\")\n",
        "    display(to_markdown(plano_de_post))\n",
        "    print(\"--------------------------------------------------------------\")\n",
        "\n",
        "    rascunho_de_post = agente_redator(topico, plano_de_post)\n",
        "    print(\"\\n--- üìù Resultado do Agente 3 (Redator) ---\\n\")\n",
        "    display(to_markdown(rascunho_de_post))\n",
        "    print(\"--------------------------------------------------------------\")\n",
        "\n",
        "    post_final = agente_revisor(topico, rascunho_de_post)\n",
        "    print(\"\\n--- üìù Resultado do Agente 4 (Revisor) ---\\n\")\n",
        "    display(to_markdown(post_final))\n",
        "    print(\"--------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6xzI6LKzxxnN",
        "outputId": "b90482c6-ada7-4a7b-c62f-0ad8a5b08faf"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Iniciando o Sistema de Cria√ß√£o de Posts para Instagram com 4 Agentes üöÄ\n",
            "‚ùì Por favor, digite o T√ìPICO sobre o qual voc√™ quer criar o post de tend√™ncias: ia\n",
            "Maravilha! Vamos ent√£o criar o post sobre novidades em ia\n",
            "\n",
            "--- üìù Resultado do Agente 1 (Buscador) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Para encontrar os lan√ßamentos de IA mais relevantes e atuais, focarei em not√≠cias e rea√ß√µes entusiasmadas das √∫ltimas semanas.\n> \n> \n> Com base nas not√≠cias e tend√™ncias atuais, aqui est√£o 5 lan√ßamentos e desenvolvimentos de IA que parecem ser os mais relevantes e entusiasmantes at√© maio de 2025:\n> \n> 1.  **OpenAI GPT-4.1 e GPT-4.1 Mini:** A OpenAI lan√ßou os modelos GPT-4.1 e GPT-4.1 Mini para usu√°rios do ChatGPT. O GPT-4.1 promete um desempenho mais r√°pido e melhorias em tarefas de programa√ß√£o, enquanto o GPT-4.1 Mini est√° acess√≠vel a todos os usu√°rios da plataforma.\n> 2.  **IA Generativa Multimodal:** A Meta AI lan√ßou a fam√≠lia de modelos Llama 4, apresentando a IA nativamente multimodal. Os modelos Llama 4 Scout e Llama 4 Maverick s√£o projetados com fus√£o inicial, pr√©-treinados com dados textuais e visuais, resultando em uma compreens√£o mais natural e intuitiva atrav√©s de diferentes modalidades.\n> 3.  **Google Gemini:** O Gemini, modelo de IA do Google, est√° expandindo sua presen√ßa para plataformas como Wear OS, Android Auto e Google TV. Al√©m disso, a Google est√° aprofundando a integra√ß√£o da IA na sua ferramenta de pesquisa e desenvolvendo uma plataforma alternativa ao Pinterest com capacidades de intelig√™ncia artificial.\n> 4.  **Scientist AI:** Um novo modelo de IA que promete guardrails para prevenir comportamentos aut√¥nomos indesejados. A abordagem Scientist AI se baseia em um modelo de compreens√£o causal do mundo, priorizando a honestidade e apresentando uma alternativa segura √† trajet√≥ria atual de IA baseada na autonomia.\n> 5.  **Automa√ß√£o Inteligente de Processos:** A automa√ß√£o inteligente, impulsionada por IA, est√° revolucionando processos diversos ao simplificar, automatizar e otimizar opera√ß√µes de maneira mais estrat√©gica. A combina√ß√£o de aprendizado de m√°quina, an√°lise avan√ßada e algoritmos permite eliminar tarefas manuais repetitivas, reduzir custos operacionais e elevar a efici√™ncia das opera√ß√µes.\n> \n> Esses lan√ßamentos representam avan√ßos significativos em diversas √°reas da IA, desde modelos de linguagem e gera√ß√£o multimodal at√© aplica√ß√µes em seguran√ßa, automa√ß√£o e sa√∫de. Eles demonstram o r√°pido crescimento e a crescente import√¢ncia da IA em v√°rios setores da sociedade.\n> \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------\n",
            "\n",
            "--- üìù Resultado do Agente 2 (Planejador) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Ok, com base nos lan√ßamentos e desenvolvimentos de IA que voc√™ listou, vou criar um plano de conte√∫do detalhado para cada um deles e, em seguida, selecionar o tema mais relevante para um post.\n> \n> **1. OpenAI GPT-4.1 e GPT-4.1 Mini:**\n> \n> *   **Pontos Relevantes:**\n>     *   Lan√ßamento dos modelos GPT-4.1 e GPT-4.1 Mini.\n>     *   GPT-4.1: Desempenho mais r√°pido e melhorias em programa√ß√£o.\n>     *   GPT-4.1 Mini: Acess√≠vel a todos os usu√°rios do ChatGPT.\n> *   **Plano de Conte√∫do:**\n>     *   Explicar o que s√£o os modelos GPT-4.1 e GPT-4.1 Mini.\n>     *   Detalhar as melhorias de desempenho do GPT-4.1, com foco em programa√ß√£o.\n>     *   Destacar a acessibilidade do GPT-4.1 Mini e como isso democratiza o acesso √† IA.\n>     *   Exemplos de casos de uso para cada modelo.\n> \n> **2. IA Generativa Multimodal (Meta AI - Llama 4):**\n> \n> *   **Pontos Relevantes:**\n>     *   Lan√ßamento da fam√≠lia de modelos Llama 4.\n>     *   IA nativamente multimodal.\n>     *   Modelos Llama 4 Scout e Llama 4 Maverick.\n>     *   Fus√£o inicial de dados textuais e visuais.\n>     *   Compreens√£o mais natural e intuitiva.\n> *   **Plano de Conte√∫do:**\n>     *   Introduzir o conceito de IA multimodal.\n>     *   Apresentar a fam√≠lia Llama 4 e seus modelos.\n>     *   Explicar a import√¢ncia da fus√£o inicial de dados textuais e visuais.\n>     *   Exemplificar como a IA multimodal melhora a compreens√£o em diferentes contextos.\n>     *   Casos de uso pr√°ticos da IA multimodal.\n> \n> **3. Google Gemini:**\n> \n> *   **Pontos Relevantes:**\n>     *   Expans√£o para Wear OS, Android Auto e Google TV.\n>     *   Integra√ß√£o aprofundada na ferramenta de pesquisa do Google.\n>     *   Desenvolvimento de plataforma alternativa ao Pinterest com IA.\n> *   **Plano de Conte√∫do:**\n>     *   Apresentar o Google Gemini e seu potencial.\n>     *   Detalhar a expans√£o para diferentes plataformas (Wear OS, Android Auto, Google TV).\n>     *   Explicar como a IA est√° sendo integrada na busca do Google.\n>     *   Apresentar a plataforma alternativa ao Pinterest e suas funcionalidades de IA.\n>     *   Discutir o impacto da IA do Google no futuro da busca e entretenimento.\n> \n> **4. Scientist AI:**\n> \n> *   **Pontos Relevantes:**\n>     *   Novo modelo de IA com \"guardrails\" para prevenir comportamentos indesejados.\n>     *   Baseado em um modelo de compreens√£o causal do mundo.\n>     *   Prioriza a honestidade.\n>     *   Alternativa segura √† IA baseada na autonomia.\n> *   **Plano de Conte√∫do:**\n>     *   Introduzir o conceito de \"guardrails\" em IA e sua import√¢ncia.\n>     *   Apresentar o Scientist AI como uma solu√ß√£o para prevenir comportamentos aut√¥nomos indesejados.\n>     *   Explicar o modelo de compreens√£o causal do mundo.\n>     *   Destacar a prioriza√ß√£o da honestidade e seguran√ßa.\n>     *   Debater a necessidade de alternativas seguras √† IA aut√¥noma.\n> \n> **5. Automa√ß√£o Inteligente de Processos:**\n> \n> *   **Pontos Relevantes:**\n>     *   Revolu√ß√£o de processos diversos.\n>     *   Simplifica√ß√£o, automa√ß√£o e otimiza√ß√£o de opera√ß√µes.\n>     *   Combina√ß√£o de aprendizado de m√°quina, an√°lise avan√ßada e algoritmos.\n>     *   Elimina√ß√£o de tarefas manuais repetitivas.\n>     *   Redu√ß√£o de custos operacionais e aumento da efici√™ncia.\n> *   **Plano de Conte√∫do:**\n>     *   Definir o que √© Automa√ß√£o Inteligente de Processos (IPA).\n>     *   Explicar como a IPA est√° transformando diferentes setores.\n>     *   Detalhar as tecnologias envolvidas (aprendizado de m√°quina, an√°lise avan√ßada, algoritmos).\n>     *   Apresentar exemplos de sucesso de IPA em empresas.\n>     *   Discutir os benef√≠cios da IPA (redu√ß√£o de custos, aumento da efici√™ncia, etc.).\n> \n> **Escolha do Tema Mais Relevante:**\n> \n> Ap√≥s analisar os temas, considero que o **Scientist AI** √© o mais relevante para um post no momento. A quest√£o da seguran√ßa e √©tica na IA √© crucial e est√° gerando muitos debates. Um modelo que prioriza a honestidade e busca prevenir comportamentos indesejados √© extremamente interessante e pode atrair muita aten√ß√£o.\n> \n> **Plano Detalhado para o Post sobre Scientist AI:**\n> \n> *   **T√≠tulo:** \"Scientist AI: A IA Honesta que Pode Mudar o Futuro da Autonomia\"\n> *   **Introdu√ß√£o:**\n>     *   Contextualizar a crescente preocupa√ß√£o com a seguran√ßa e √©tica na IA.\n>     *   Apresentar o Scientist AI como uma solu√ß√£o inovadora.\n> *   **O que √© Scientist AI:**\n>     *   Explicar que √© um novo modelo de IA com \"guardrails\" para prevenir comportamentos aut√¥nomos indesejados.\n>     *   Detalhar que ele √© baseado em um modelo de compreens√£o causal do mundo.\n> *   **Por que a Honestidade √© Importante:**\n>     *   Discutir os riscos de uma IA aut√¥noma sem valores √©ticos.\n>     *   Explicar como o Scientist AI prioriza a honestidade em suas decis√µes.\n> *   **Como o Scientist AI Funciona:**\n>     *   Detalhar o modelo de compreens√£o causal do mundo.\n>     *   Explicar como os \"guardrails\" previnem comportamentos indesejados.\n> *   **Aplica√ß√µes e Impacto:**\n>     *   Discutir poss√≠veis aplica√ß√µes do Scientist AI em diferentes setores.\n>     *   Analisar o impacto potencial na seguran√ßa e √©tica da IA.\n> *   **Conclus√£o:**\n>     *   Reafirmar a import√¢ncia de modelos de IA seguros e √©ticos.\n>     *   Incentivar a discuss√£o sobre o futuro da IA e a necessidade de \"guardrails\".\n> *   **Call to Action:**\n>     *   Convidar os leitores a compartilhar suas opini√µes sobre o Scientist AI e a seguran√ßa da IA.\n> \n> Agora que temos um plano detalhado, podemos criar um post envolvente e informativo sobre o Scientist AI!\n> \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-36 (_asyncio_thread_main):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 138, in _asyncio_thread_main\n",
            "    asyncio.run(_invoke_run_async())\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 190, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
            "    return future.result()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 126, in _invoke_run_async\n",
            "    async for event in self.run_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 197, in run_async\n",
            "    async for event in invocation_context.agent.run_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/agents/base_agent.py\", line 133, in run_async\n",
            "    async for event in self._run_async_impl(ctx):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/agents/llm_agent.py\", line 246, in _run_async_impl\n",
            "    async for event in self._llm_flow.run_async(ctx):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 243, in run_async\n",
            "    async for event in self._run_one_step_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 268, in _run_one_step_async\n",
            "    async for llm_response in self._call_llm_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 483, in _call_llm_async\n",
            "    async for llm_response in llm.generate_content_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/models/google_llm.py\", line 140, in generate_content_async\n",
            "    response = await self.api_client.aio.models.generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/models.py\", line 6672, in generate_content\n",
            "    response = await self._generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/models.py\", line 5674, in _generate_content\n",
            "    response_dict = await self._api_client.async_request(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 789, in async_request\n",
            "    result = await self._async_request(http_request=http_request, stream=False)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 733, in _async_request\n",
            "    await errors.APIError.raise_for_async_response(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/errors.py\", line 129, in raise_for_async_response\n",
            "    raise ClientError(status_code, response_json, response)\n",
            "google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': \"Gemini 2.5 Pro Preview doesn't have a free quota tier. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\", 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro-exp'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro-exp', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro-exp'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerDay-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro-exp'}}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '3s'}]}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- üìù Resultado do Agente 3 (Redator) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ""
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-38 (_asyncio_thread_main):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 138, in _asyncio_thread_main\n",
            "    asyncio.run(_invoke_run_async())\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 190, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
            "    return future.result()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 126, in _invoke_run_async\n",
            "    async for event in self.run_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 197, in run_async\n",
            "    async for event in invocation_context.agent.run_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/agents/base_agent.py\", line 133, in run_async\n",
            "    async for event in self._run_async_impl(ctx):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/agents/llm_agent.py\", line 246, in _run_async_impl\n",
            "    async for event in self._llm_flow.run_async(ctx):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 243, in run_async\n",
            "    async for event in self._run_one_step_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 268, in _run_one_step_async\n",
            "    async for llm_response in self._call_llm_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 483, in _call_llm_async\n",
            "    async for llm_response in llm.generate_content_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/models/google_llm.py\", line 140, in generate_content_async\n",
            "    response = await self.api_client.aio.models.generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/models.py\", line 6672, in generate_content\n",
            "    response = await self._generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/models.py\", line 5674, in _generate_content\n",
            "    response_dict = await self._api_client.async_request(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 789, in async_request\n",
            "    result = await self._async_request(http_request=http_request, stream=False)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 733, in _async_request\n",
            "    await errors.APIError.raise_for_async_response(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/errors.py\", line 129, in raise_for_async_response\n",
            "    raise ClientError(status_code, response_json, response)\n",
            "google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': \"Gemini 2.5 Pro Preview doesn't have a free quota tier. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\", 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro-exp', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro-exp'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro-exp'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerDay-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro-exp'}}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '2s'}]}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- üìù Resultado do Agente 4 (Revisor) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ""
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}